scale_y_continuous(name="r/wallstreebets Average Sentiment", sec.axis = sec_axis(~.*290,name="SPY $ Differential")) +
xlab("Date") +
ggtitle("Average Daily WSB Sentiment Compared to SPY Daily Change") +
scale_color_manual("Plot Lines",values = c("Sentiment"="red","Differential"="blue")) +
scale_x_date(date_breaks = "2 month",
limits = as.Date(c('2020-01-01','2020-07-01'))) +
theme(legend.position = c(0.12,0.85))
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avg_sent, color='Sentiment')) +
geom_line(aes(y=differential / 290, color='Differential')) +
scale_y_continuous(name="r/wallstreebets Average Sentiment", sec.axis = sec_axis(~.*290,name="SPY $ Differential")) +
xlab("Date") +
ggtitle("Average Daily WSB Sentiment Compared to SPY Daily Change") +
scale_color_manual("Plot Lines",values = c("Sentiment"="red","Differential"="blue")) +
scale_x_date(date_breaks = "2 month",
limits = as.Date(c('2019-07-01','2020-01-01'))) +
theme(legend.position = c(0.12,0.85))
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avg_sent, color='Sentiment')) +
geom_line(aes(y=differential / 290, color='Differential')) +
scale_y_continuous(name="r/wallstreebets Average Sentiment", sec.axis = sec_axis(~.*290,name="SPY $ Differential")) +
xlab("Date") +
ggtitle("Average Daily WSB Sentiment Compared to SPY Daily Change") +
scale_color_manual("Plot Lines",values = c("Sentiment"="red","Differential"="blue")) +
scale_x_date(date_breaks = "2 month",
limits = as.Date(c('2019-02-19','2019-07-01'))) +
theme(legend.position = c(0.12,0.85))
combined.sub.df <- combined.df[combined.df$day > as.Date("2020-06-01")]
combined.sub.df <- combined.df[combined.df$day > as.Date("2020-06-01"),]
cor(combined.sub.df$avg_sent,combined.sub.df$differential)
combined.sub.df <- combined.df[combined.df$day > as.Date("2020-06-01") | combined.df$day < as.Date("2020-02-01"),]
cor(combined.sub.df$avg_sent,combined.sub.df$differential)
prior5_spy <- hist.spy.df
prior5_spy$Date <- prior5_spy$Date - 3
prior_spy <- hist.spy.df
prior_spy$Date <- prior5_spy$Date - 3
combinedprior.df <- merge(wsb.agg.df,prior_spy, by.x="day",by.y="Date")
cor(cor(combinedprior.df$avg_sent,combinedprior.df$differential))
cor(combinedprior.df$avg_sent,combinedprior.df$differential)
prior_spy$Date <- prior5_spy$Date - 2
combinedprior.df <- merge(wsb.agg.df,prior_spy, by.x="day",by.y="Date")
cor(combinedprior.df$avg_sent,combinedprior.df$differential)
prior_spy <- hist.spy.df
prior_spy$Date <- prior5_spy$Date - 5
combinedprior.df <- merge(wsb.agg.df,prior_spy, by.x="day",by.y="Date")
cor(combinedprior.df$avg_sent,combinedprior.df$differential)
library(dplyr)
combined.df$sent_cumsum <- cumsum(combined.df$total_sent)
xlab("Date") +
ggtitle("Cumulative Sentiment of WSB")
xlab("Date") +
ggtitle("Cumulative Sentiment of WSB")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=sent_cumsum, color='blue')) +
ylab("Cumulative Sentiment") +
xlab("Date") +
ggtitle("Cumulative Sentiment of WSB")
# Calculate cumulative average sentiment
combined.df$avgsent_cumsum <- cumsum(combined.df$avg_sent)
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='blue')) +
ylab("Cumulative Sentiment") +
xlab("Date") +
ggtitle("Cumulative Sentiment of WSB")
max(combined.df$Close)
max(combined.df$avgsent_cumsum)
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='Differential')) +
scale_y_continuous(name="r/wallstreebets Average Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
ylab("Cumulative Average Sentiment") +
xlab("Date") +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='Differential')) +
scale_y_continuous(name="r/wallstreebets Average Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
ylab("Cumulative Average Sentiment") +
xlab("Date") +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
+ theme(legend.position = c(0.12,0.85))
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='Differential')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
ylab("Cumulative Average Sentiment") +
xlab("Date") +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
+ theme(legend.position = c(0.12,0.85))
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='Differential')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
ylab("Cumulative Average Sentiment") +
xlab("Date") +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='SPY Close')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
xlab("Date") +
scale_color_manual("Plot Lines",values = c("Avg Sent Sum"="red","SPY Close"="cyan")) +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='SPY Close')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
xlab("Date") +
scale_color_manual("Plot Lines",values = c("Avg Sent Sum"="red","SPY Close"="cyan4")) +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='SPY Close')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
xlab("Date") +
scale_color_manual("Plot Lines",values = c("Avg Sent Sum"="red4","SPY Close"="cyan4")) +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='SPY Close')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
xlab("Date") +
scale_color_manual("Plot Lines",values = c("Avg Sent Sum"="red2","SPY Close"="cyan4")) +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='SPY Close')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
xlab("Date") +
scale_color_manual("Plot Lines",values = c("Avg Sent Sum"="red2","SPY Close"="cyan3")) +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value")
ggplot(combined.df, aes(x=day)) +
geom_line(aes(y=avgsent_cumsum, color='Avg Sent Sum')) +
geom_line(aes(y=Close / 129, color='SPY Close')) +
scale_y_continuous(name="r/wallstreebets Average Cumulative Sentiment", sec.axis = sec_axis(~.*129,name="SPY $ Close")) +
xlab("Date") +
scale_color_manual("Plot Lines",values = c("Avg Sent Sum"="red2","SPY Close"="cyan3")) +
ggtitle("Cumulative Average Sentiment of WSB with SPY Closing Value") +
theme(legend.position = c(0.8,0.2))
# See correlation of close and cumulative average sentiment
cor(combined.df$avgsent_cumsum,combined.df$Close)
library(gridExtra)
library(ggpubr)
install.packages(ggpubr)
install.packages("ggpubr")
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject//data/wsb_chunk144.csv")
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk144.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk14.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk15.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk16.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk17.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk31.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk30.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk29.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk28.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk27.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk26.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk25.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk24.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk23.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk22.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk21.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk20.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk350.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk340.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk300.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk280.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk230.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk250.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk21.csv",nrows=10)
wsb_chunk_test <- read.csv("/Users/ohammond/Documents/605/605FinalProject/data_test/wsb_chunk20.csv",nrows=10)
to_datetime(1608445534)
as_datetime(1608445534)
as_datetime(1608416008)
?lexicon::hash_sentiment_jockers_rinker
require(dplyr)
# Find correlation value
cor(combined.df$avg_sent,combined.df$differential)
# Find correlation value
cat(cor(combined.df$avg_sent,combined.df$differential),stout())
# Find correlation value
cat(cor(combined.df$avg_sent,combined.df$differential),stdout())
# Find correlation value
cat(paste("SPY Sentiment Correlation:", cor(combined.df$avg_sent,combined.df$differential)),stdout())
library(ggplot2)
library(dplyr)
library(tidyverse)
#'Create dataframe with following columns for running different models:
#'County
#'FIPS
#'Number of Cases per 100k after start date within days.after
#'Number of Cases per 100k before start date within days.prior
#'Mask Mandate Status (0 for no mandate, 1 for mandate)
#'Vaccination Percentage
#'Political Party Percentage (percentage republican)
#'Population Density
create.mask.df <- function(start.date,days.after,days.prior, vacc.date=start.date) {
as.Date(start.date)
fullcases.df <- read.csv("/Users/ohammond/Downloads/us-counties.csv")
fullcases.df$date <- as.Date(fullcases.df$date)
# Get City CSV
city.list <- read.csv("/Users/ohammond/Downloads/NYP_City_List - NYP_City_List.csv",fileEncoding = "UTF-8-BOM")
city.cases.df <- filter(fullcases.df, fips %in% city.list$fips)
# Calculate number of cases in post interval
cases.start.df <- city.cases.df[city.cases.df$date == start.date, ]
cases.end.df <-city.cases.df[city.cases.df$date == (start.date + days.after), ]
cases.start.df$post.cases <- cases.end.df$cases - cases.start.df$cases
# Add post cases to city dataframe
combined.df <- merge(city.list, cases.start.df, by.x="fips", by.y = "fips")
# Calculate number of cases in prior  interval
prior.cases.start.df <-city.cases.df[city.cases.df$date == (start.date - days.prior), ]
prior.cases.end.df <- city.cases.df[city.cases.df$date == start.date, ]
prior.cases.start.df$prior.cases <- prior.cases.end.df$cases - prior.cases.start.df$cases
# Add prior cases to city dataframe
combined.df <- merge(combined.df, prior.cases.start.df, by.x="fips", by.y = "fips")
# Turn cases into cases per 100k
combined.df$post.cases <- (combined.df$post.cases / combined.df$population) * 100000
combined.df$prior.cases <- (combined.df$prior.cases /combined.df$population) * 100000
# Add vaccination rates
vaccination.df <- read.csv("/Users/ohammond/Downloads/casevac.csv")
vaccination.df$date <- as.Date(vaccination.df$date)
vaccination.df <- vaccination.df[vaccination.df$date == start.date, ]
# Merge vaccination rates
combined.df <- merge(combined.df, vaccination.df[, c("fips","Series_Complete_Pop_Pct")], by="fips")
# Remove % sign from the republican and democratic columns, convert to numeric and divide by 100.
combined.df$Republican <- as.numeric(sub("%","",combined.df$Republican))/100
combined.df$Democrat <- as.numeric(sub("%","",combined.df$Democrat))/100
# Rename Mask Mandate Column
combined.df <- rename(combined.df, mask.mandate = Mask.Mandate)
# Remove the columns we don't care about
combined.df$mask.mandate <- as.factor(combined.df$mask.mandate)
return(combined.df)
}
start.date = as.Date("2021-08-21")
days.after=60
days.prior = 14
vacc.date <- start.date
mask.df <- create.mask.df(start.date, days.after, days.prior)
prior_mask_lm <- lm(post.cases ~ prior.cases + mask.mandate,data=mask.df)
summary(prior_mask_lm)
mask_lm <- lm(post.cases ~ mask.mandate,data=mask.df)
summary(mask_lm)
mask.df[,c(1,2,3,4)]
mask.df[,c(1:4)]
mask.df[,c(1:10,12,18,24,25)]
mask_selected.df <- mask.df[,c(1:10,12,18,24,25)]
write.csv(mask_selected.df,file = "/Users/ohammond/Downloads/maskdf.csv")
hlm_mask_model <- lmer(post.cases ~ prior.cases + mask.mandate + (1|Democrat),data=mask.df)
library(lme4)
hlm_mask_model <- lmer(post.cases ~ prior.cases + mask.mandate + (1|Democrat),data=mask.df)
matrix(c(-1,0,1,0,-1,-1,0,1,-1,1,-1,1,0,0,1,0,0,-1,1,0,-1,0,1,0),nrow = 6)
s1 <-matrix(c(-1,0,1,0,-1,-1,0,1,-1,1,-1,1,0,0,1,0,0,-1,1,0,-1,0,1,0),nrow = 6)
t(s1)*s1
t(s1)%*%s1
solve(t(s1)%*%s1)
s1
s1 <-matrix(c(-1,0,1,0,-1,-1,0,1,-1,1,-1,1,0,0,1,0,0,-1,1,0,-1,0,1,0),nrow = 6,byrow = True)
s1 <-matrix(c(-1,0,1,0,-1,-1,0,1,-1,1,-1,1,0,0,1,0,0,-1,1,0,-1,0,1,0),nrow = 6,byrow = TRUE)
s1
solve(t(s1)%*%s1)
t(s1)
t(s1)%*%s1
s1
t(s1)
t(s1)%*%s1
require(matlib)
install.packages("matlib")
require(matlib)
inv(t(s1)%*%s1)
library(matlib)
inv(s1)
s1
t(s1)
t(s1)%*%s1
solve(t(s1)%*%s1)
qq_test <- c(rnorm(20,0,2),rnorm(20,1,3),rnorm(20,2,4),rnorm(20,3,5))
qq_norm(qq_test)
qqnorm(qq_test)
qq_test <- c(rnorm(20,0,2),rnorm(20,1,2),rnorm(20,2,2),rnorm(20,3,2))
qqnorm(qq_test)
qq_test <- c(rnorm(20,0,2),rnorm(20,0,2),rnorm(20,0,2),rnorm(20,0,2))
qqnorm(qq_test)
qq_test <- c(rnorm(20,0,2),rnorm(20,0,10),rnorm(20,0,20),rnorm(20,0,40))
qqnorm(qq_test)
qqline()
qqline(qq_test)
qq_test <- c(rnorm(20,0,2),rnorm(20,10,10),rnorm(20,20,20),rnorm(20,40,40))
qqnorm(qq_test)
qqline(qq_test)
hours <- c(2.4,4.6,4.8,2.7,4.2,4.5,2.3,4.9,4.4,2.5,4.7,4.6,5.8,8.9,9.1,5.2,9.1,9.3,5.5,8.7,8.7,5.3,9.0,9.4,6.1,9.9,13.5,5.7,10.5,13,5.9,10.6,13.3,6.2,10.1,13.2)
A <- as.factor(c(rep("L",4),rep("M",4),rep("H",4))
)
B <- as.factor(c(rep(c(1,2,3),12)))
res3.aov = aov(hours ~ A * B)
len(A)
shape(A)
A <- as.factor(c(rep("L",12),rep("M",12),rep("H",12)))
res3.aov = aov(hours ~ A * B)
summary(res3.aov)
dat = structure(list(Day = c("D1", "D1", "D1", "D1", "D2", "D2", "D2",
"D2", "D3", "D3", "D3", "D3", "D4", "D4", "D4", "D4", "D5", "D5",
"D5", "D5", "D6", "D6", "D6", "D6"),
P = c(360L, 360L, 360L,
360L, 370L, 370L, 370L, 370L, 380L, 380L, 380L, 380L, 380L, 380L,
380L, 380L, 370L, 370L, 370L, 370L, 360L, 360L, 360L, 360L),
Q = c("C2", "C3", "C1", "C4", "C1", "C3", "C4", "C2", "C3",
"C1", "C2", "C4", "C4", "C3", "C2", "C1", "C4", "C1", "C3",
"C2", "C1", "C4", "C2", "C3"),
y = c(73L, 83L, 67L, 89L,
65L, 87L, 86L, 91L, 147L, 155L, 127L, 212L, 153L, 90L, 100L,
108L, 150L, 140L, 121L, 142L, 33L, 54L, 8L, 46L)),
class = "data.frame", row.names = c(NA,-24L))
dat$P = as.factor(dat$P)
# Follow the ANOVA table order
fit1 = aov(y ~ P + Error(Day) + Q + P:Q, data = dat)
summary(fit1)
mean(hours)
hours[:4]
hours(:4)
hours[0:4]
hours[1:4]
dat_df <- data.frame("hours" = hours, "A" = A, "B"=B)
dat_df
aggregate(dat_df$hours,list(dat_df$A,dat_df$B), FUN=mean)
aggregate(dat_df$hours,list(dat_df$A), FUN=mean)
aggregate(dat_df$hours,list(dat_df$A), FUN=mean) - 7.183
aggregate(dat_df$hours,list(dat_df$B), FUN=mean) - 7.183
merge(aggregate(dat_df$hours,list(dat_df$A,dat_df$B), FUN=mean),aggregate(dat_df$hours,list(dat_df$A), FUN=mean))
aggregate(dat_df$hours,list(dat_df$A), FUN=mean)
merge(aggregate(dat_df$hours,list(dat_df$A,dat_df$B), FUN=mean),aggregate(dat_df$hours,list(dat_df$A), FUN=mean),by=Group.1)
gmeans <- aggregate(dat_df$hours,list(dat_df$A,dat_df$B), FUN=mean)
gmeans
ameans <- aggregate(dat_df$hours,list(dat_df$A), FUN=mean)
ameans
merge(gmeans,ameans)
ameans["Group.1"]
merge(gmeans,ameans,all=TRUE)
merge(gmeans,ameans,by.x = Group.1,by.y = Group.1)
bmeans <- aggregate(dat_df$hours,list(dat_df$B), FUN=mean)
gmeans
ameans
bmeans
merge(gmeans,ameans,by.x = "Group.1",by.y = "Group.1")
names(ameans)
names(ameans)[2]
names(ameans)[2] <- "mu_A"
names(bmeans)[2] <-
"mu_B"
bmeans
mean_df <- merge(gmeans,ameans,by.x = "Group.1",by.y = "Group.1")
merge(mean_df,bmeans,by.x="Group.2",by.y="Group.1")
mean_df <- merge(mean_df,bmeans,by.x="Group.2",by.y="Group.1")
mean_df$x - mean_df$mu_A - mean_df$mu_B + 7.183
mean_df$pq <- mean_df$x - mean_df$mu_A - mean_df$mu_B + 7.183
mean_df
sum(mean_df$pq)
options(contrasts = c("contr.sum","contr.sum"))
summary(lm(hours ~ A+B+A*B))
options(contrasts = c("contr.sum","contr.sum","contr.sum"))
full <- summary(lm(hours ~ A+B+A*B))
full$residuals
plot(full$residuals - full$fitted, ylab="Residuals",xlab= "Cell Means")
plot(full$residuals ~ full$fitted, ylab="Residuals",xlab= "Cell Means")
full <- lm(hours ~ A+B+A*B)
plot(full$residuals ~ full$fitted, ylab="Residuals",xlab= "Cell Means")
title("Constant Variance Plot")
plot(full)
res3.aov = aov(hours ~ A * B)
summary(res3.aov)
res3.aov
fit2 <- aov(hours ~ A)
summary(fit2)
anova(res3.aov,fit2)
1.27*sqrt(0.25)
sqrt{9*2.2501}
sqrt(9*2.2501)
0.635*4.5
8*2.3053
sqrt(18.4424)
1.27*sqrt(0.5)
4.6-2.475
4.294 *0.898
library(dplyr)
library(car)
time <- c(62,60,63,59, 63,67,71,64,65,66,68,66,71,67,68,68,56, 62,60,61,63,64,63,59)
poison <- as.factor(rep(c('A','B','C','D'),c(6,6,6,6)))
dat = data.frame(time,poison)
fit = lm(time~., data = dat)
anova(fit)
mu_t = dat %>%
group_by(poison)%>%
summarise(m = mean(time)) %>%
.[,2,drop = F] %>%
as.matrix()
mu_t
levels(dat_df$A)
levels(dat_df$A) <- c(3,1,2)
dat_df
mean_df
levels(mean_df$Group.1)
levels(mean_df$Group.1) <- c(3,1,2)
mean_df
mean_df[1,1]$x
mean_df %>% tidyr::pivot_wider(names_from = Group.2,values_from = x)
gmeans
mean_df
gmeans %>% tidyr::pivot_wider(names_from = Group.2,values_from = x)
pivotg <- gmeans %>% tidyr::pivot_wider(names_from = Group.2,values_from = x)
pivotg
pivotg[1]
pivotg[1,1]
pivotg[1,2]
pivotg[3,2]
pivotg[3,4]
pivotg %*% C(1,0,-1,0)
pivotg %*% c(1,0,-1,0)
pivotg %*% t(c(1,0,-1,0))
pivotg
mean_df
mean_df[with(mean_df,order(Group.1,Group.2))]
mean_df[with(mean_df,order(Group.1,Group.2)),]
TukeyHSD(res3.aov,conf.level = 0.9)
source("~/Downloads/Dis9.R")
summary(fit1)
summary(full)
full <- lm(hours ~ A+B+A*B)
res <- MASS::boxcox(full)
res$x[which.max(res$y)]
dat_df$hours_t = dat_df$hours^(0.7878)
dat_df
lm(hours_t ~ A*B, data = dat_df)
fit_n <- lm(hours_t ~ A*B, data = dat_df)
summary(fit_n)
aov(hours_t ~ A*B, data=dat_df)
aov_t <- aov(hours_t ~ A*B, data=dat_df)
summary(aov_t)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
R.Version()
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
arch <- ifelse(R.version$arch == "aarch64", "arm64", "x86_64")
cat(paste("\nCXX14FLAGS += -O3 -mtune=native -arch", arch, "-ftemplate-depth-256"),
file = M, sep = "\n", append = FALSE)
Sys.setenv(MAKEFLAGS = "-j4") # four cores used
install.packages(c("Rcpp", "RcppEigen", "RcppParallel", "StanHeaders"), type = "source")
install.packages("rstan", type = "source")
import(rstan)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
J <- 8
y <- [28,  8, -3,  7, -1,  1, 18, 12]
sigma <- [15, 10, 16, 11,  9, 11, 10, 18]
y <- c(28,  8, -3,  7, -1,  1, 18, 12)
sigma <-c(15, 10, 16, 11,  9, 11, 10, 18)
mu0 <- 0
tau <- 250
pooled_model <- rstan::stan_model(file='eight_schools_pooled.stan')
setwd("~/Documents/775")
pooled_model <- rstan::stan_model(file='eight_schools_pooled.stan')
View(pooled_model)
pooled_args <- list(J=J, y=y, sigma=sigma, mu0=mu0, tau=tau)
pooled_fit <- rstan::sampling(object = pooled_model,
data = pooled_args)
rstan::summary(pooled_fit)[[1]]
pooled_fit <- rstan::sampling(object = pooled_model,
data = pooled_args,
chains = 8, iter = 10000)
rstan::summary(pooled_fit)[[2]]
rstan::summary(pooled_fit)[[1]]
rstan::summary(pooled_fit)[1]
pooled_examples <- rstan::extract(object = pooled_fit,
pars = c("mu"))[['mu']]
mean(pooled_samples > 0)
pooled_samples <- rstan::extract(object = pooled_fit,
pars = c("mu"))[['mu']]
mean(pooled_samples > 0)
c(MCMC = mean(pooled_samples),
exact = sqrt(1/sum(1/(sigma*sigma)) + 1/(250^2)))
c(MCMC = sd(pooled_samples),
exact = sqrt(1/sum(1/(sigma*sigma)) + 1/(250^2)))
c(MCMC = sd(pooled_samples),
exact = sum(y/(sigma^2))/(sum(1/(sigma^2))+1/(tau^2)))
c(MCMC = mean(pooled_samples),
exact = sum(y/(sigma^2))/(sum(1/(sigma^2))+1/(tau^2)))
pooled_model <- rstan::stan_model(file='eight_schools_unpooled.stan')
unpooled_model <- rstan::stan_model(file='eight_schools_unpooled.stan')
unpooled_args <- list(J=J, y=y, sigma=sigma, mu0=mu0, tau=tau)
unpooled_fit <- rstan::sampling(object = unpooled_model,
data = unpooled_args,
chains = 8, iter = 10000)
rstan::summary(unpooled_fit)[[1]]
unpooled_samples <- rstan::extract(object = unpooled_fit,
pars = c("mu"))[['mu']]
dim(unpooled_ssamples)
dim(unpooled_samples)
mean(unpooled_samples,axis=1)
mean(unpooled_samples,axis=0)
mean(unpooled_samples)
mean(unpooled_samples, axis=2)
apply(unpooled_samples, MARGIN = 2, FUN=mean)
rm(list=ls())
install.packages("rjson")
library("rjson")
reviews <- fromJSON(file='../../../data/yelp_dataset_2022/business.json')
setwd("~/Documents/628/Stat628-Module3/code/experimentation/Oliver")
reviews <- fromJSON(file='../../../data/yelp_dataset_2022/business.json')
businesses <- fromJSON(file='../../../data/yelp_dataset_2022/business.json')
businesses <- rjson::fromJSON(file='../../../data/yelp_dataset_2022/business.json')
